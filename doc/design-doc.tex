\documentclass[]{article}

\usepackage{geometry}
\usepackage{marginnote}

\usepackage{hyperref}

% Copyright
%\setcopyright{usgovmixed}

% DOI
%\acmDOI{}

% ISBN
%\acmISBN{}

% Conference
%cmConference[VPA17]{Fourth International Workshop on Visual Performance Analysis}{November 2017}{Denver, Colorado USA}
%\acmYear{2017}
%\copyrightyear{2017}

\begin{document}

\title{The Hedgehog Numerical Linear Algebra Library}

\author{Timothy Blattner \and Gerson Kroiz \and Alexandre Bardakoff \and Walid Keyrouz}



%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%
%\begin{CCSXML}
%\end{CCSXML}

%\ccsdesc[]{}

%\keywords{}

\maketitle

\begin{abstract}
	The objective of this research is to develop a library of data objects and tasks that can be strung together to form complex parallel algorithms based around numerical linear algebra.
	
	We will be exploring the use of the Hedgehog API, which is the next version of the Hybrid Task Graph Scheduler (HTGS) API, to expose coarse-grained parallelism in numerical linear algebra libraries such that a partial result of an operation can be sent to the next stage of computation while the remainder of the matrix is still being processed.	
\end{abstract}

\section{Introduction}

Hedgehog represents the next generation of the Hybrid Task Graph Scheduler (HTGS). Hedgehog is an approach that aims at obtaining performance on systems with multiple CPUs and GPUs. There are three components: (1) an abstract execution model, (2) a framework, and (3) an API. The abstract execution model is used to map an algorithm into a task graph that executes the core computational kernels using coarse-grained parallelism. The Hedgehog framework provides functionality to build the task graph, which is made up a series of vertices and edges. A vertex represents a task (or a graph), which can manage state or execute computation on data that is sent to the task. Edges connect these tasks to encode data dependencies. The Hedgehog API implements this framework.

\textbf{HTGS and Hedgehog represents an algorithm's components explicitly as a task graph} and provides a separation of concerns between in-core compute kernels, orchestration, memory management, state maintenance, and data motion. This explicit representation enables users to develop, profile, and debug algorithms at a higher level of abstraction.

The primary contribution of this study is to study a novel way of representing numerical linear algebra routines, and how they can be strung together to form complex applications. We anticipate that by formulating a library in this way that CPU usage will be driven by the most compute intensive component, and will be kept busy. This will result in better performance for end-to-end applications that rely on these routines.


\section{HTGS Overview}

Developing an algoritm with HTGS requires four components; (1) Tasks, (2) Data, (3) Mandatory/optional interface functions, and (4) A main function to build the graph and interact with it. 


\begin{description}
\item[Tasks] \hfill \\
	A task in its simplest form consumes data that is sent from its input edge, processes that data, and then produces data onto its output edge. The input and output types are represented using templates, for example; $FooTask<T, U>$ defines $T$ and $U$ as the input and output data types of $FooTask$, respectively. A task can only have one output edge, but may have multiple input edges (except the bookkeeper, who can have multiple input edges and multiple output edges). If a task is connected via an edge, then the output of the producer task should match the input type of the consumer task.
	
	HTGS implements four complex tasks; CUDATask, Bookkeeper, MemoryManager, and ExecutionPipeline. Each complex task will have additional constraints beyond just a simple task.  For example, the Bookkeeper is responsible for managing complex data dependencies. The functionality for this task is defined by implementing rules. Each rule has its own input and output types (the input type matches the bookkeeper type), where the developer must define how/when the rule will produce data. These rules are typically accessed synchronously with a mutex lock, which will ensure only a single thread accesses each rule. 
	
    HTGS tasks use multi-threading to improve their data consumption rates. The number of threads associated with a task is passed to the constructor. This will cause the task to be copied, binding each copy to a separate thread.
	
\item[Data] \hfill \\	
	Data in HTGS is a class container that inherits the HTGS IData interface. The input and output types of all tasks are required to use the IData interface. These containers obtain contain pointers to data and fulfill parameter requirements for task kernels.
	
\item[Mandatory/optional interface functions] \hfill \\
	The HTGS task interface contains two mandatory and five optional interface (virtual) functions.
	
	\textbf{Mandatory Virtual Functions}
	\begin{enumerate}
	\item $\mathrm{executeTask(data)}$
		\begin{itemize}
		\item The task will consume data and then call the $\mathrm{executeTask}$ function on that data. The programmer-implementation of $\mathrm{executeTask}$ defines the functionality of the task.
		\end{itemize}
	\item $\mathrm{copy()}$
		\begin{itemize}
		\item Defines how to copy the task and potentially share data between multiple instances of the task (used for multi-threading)
		\end{itemize}
	\end{enumerate}

	\textbf{Optional Virtual Functions}
	\begin{enumerate}
	\item $\mathrm{initialize()}$
		\begin{itemize}
		\item Called after a thread is bound to the task's instance (one instance per thread). Commonly used for binding the thread to a co-processor or allocating thread-local memory.
		\end{itemize}
	\item $\mathrm{shutdown()}$
		\begin{itemize}
		\item Called prior to termination of the thread that is bound to this task's instance. Commonly used to release any bindings to co-processors or deallocating thread-local memory.
		\end{itemize}	
	\item $\mathrm{getName()}$
		\begin{itemize}
		\item Gets the human-readable name of the task. Used to aid in task graph visualization.
		\end{itemize}		
	\item $\mathrm{executeTaskFinal()}$
		\begin{itemize}
		\item Called prior to shutdown by the last thread of the task. Commonly used for parallel reductions.
		\end{itemize}		
	\item $\mathrm{canTerminate(inputConnector)}$
		\begin{itemize}
		\item Called in the execution loop for each task. Used to customize the termination behavior of the task, such as when there is a cycle in the graph. By default the task will terminate when there is no longer any tasks producing data for the inputConnector (input queue).
		\end{itemize}		
	\end{enumerate}

	Once a task has implemented the mandatory functions, then that task can be compiled and inserted into graphs. The optional functions allow for further customization to support a wide variety of architectures and algorithms.

\item[Main Function] \hfill \\
	The main function is used to allocate instances of the tasks, build the HTGS task graph, launch the graph, produce data for the graph, consume data from the output of a graph, wait for the graph to complete, and release graph memory. Each HTGS graph can have an input type and output type. The input of the graph can be bound to any task to consume data that is produced for the graph. Likewise, the output of the graph can be bound to multiple tasks to send produce data for the graph.
	
\end{description}

\section{Hedgehog Overview}
Developing an algorithm with Hedgehog requires three components; (1) Tasks, (2) Mandatory/optional interface functions, and (3) A main function to build the graph and interact with it. Unlike HTGS, Hedgehog does not require a representation of Data.

\begin{description}
	\item[AbstractTask] \hfill \\
		The abstract task consumes data of multiple input types from its input edges, and produces one output type. Each input type is bound to a separate execution function, which must be implemented. Each of these execute functions can push data to the next task(s) using \textit{addResult}, which will broadcast the output to all connected tasks. $AbstractTask<Output, Inputs...>$, defines the abstract task with the single output, and multiple inputs. For example, $FooTask<float, int, float, double>$, would have output type $std::shared\_ptr<float>$ and input types $std::shared\_ptr<int>$, $std::shared\_ptr<float>$, and $std::shared\_ptr<double>$.
		
		An abstract task uses multi-threading that is similar to HTGS. The number of threads (copies) of the task is passed to the constructor, which will then create a copy of that task and bind each copy to a separate thread.
		
	\item[Mandatory/optional inferface functions] \hfill \\
		The AbstractTask interface contains one mandatory function and four optional functions.
		\begin{description}
			\item[Mandatory Virtual Functions] \hfill \\
			\begin{enumerate}
				\item void execute($std::shared\_ptr<Input>$ data)
				\begin{itemize}
					\item There will be one execute for each input type for the task. The task will consume data of the specified type \emph{Input} and call the appropriate execute function. The programmer then will implement execute on that data, which might transform the data into the output type and call \textit{addResult}.					
				\end{itemize}		
			\end{enumerate}
			\item[Optional Virtual Functions] \hfill \\
			\begin{enumerate}
				\item void initialize()
				\begin{itemize}
					\item Called after a thread is bound to the task's instance (one instance per thread). Commonly used for binding the thread to a co-processor or allocating thread-local memory.
				\end{itemize}
				\item void shutdown()
				\begin{itemize}
					\item Called prior to termination of the thread that is bound to this task instance. Commonly used to rlease any bindings to co-processors or deallocating thread-local memory.
				\end{itemize}
				\item bool canTerminate()
				\begin{itemize}
					\item Called in the execution loop for each task. Used to customize the termination behavior of the task, such as when there is a cycle in the graph. By default the task will terminate when there is no longer any tasks producing data and there are no items in the queue.
				\end{itemize}
				\item $std::shared\_ptr<AbstractTask<TaskOutput, TaskInputs...>>$ copy()
				\begin{itemize}
					\item Defines how to copy the task and potentially share data between multiple instances of the task (used for multi-threading). This function becomes mandatory for a task if multi-threading is enabled.
				\end{itemize}
			\end{enumerate}
		\end{description}
	
\end{description}

\section{Matrix Library Overview}
The Matrix Library is an \textbf{under-development} numerical linear algebra library, which uses Basic Linear Algebra Subprograms (BLAS) that are implemented by OpenBLAS. As such, many of the abstractions presented may change. The library creates wrappers around these Subprograms to assist in computing large matrix operations. The size of these matrices will be quite large such that we can take advantage of coarse-grained parallelism by decomposing the matrix into blocks or panels and feed these into a pipeline to overlap computation with data motion. By decomposing things in this way, we can take advantage of multi and many-core systems (on the range of 16 to 40 physical CPU cores per node and above). The library will focus around the idea of sending sub-regions of a matrix between compute elements.

\subsection{Data Representation}
The primary way we are representing data in the Matrix Library will evolve around \emph{MatrixData}. This data class is expanded to represent all the different types of data needed for each operation. In the following sections, we will go over some these data representations.

\subsubsection{template $<$class Type, char Id = `0', Ord = Order::Row$>$ class MatrixData}

One thing to keep in mind with \emph{MatrixData} is the data it is pointing too is a sub-region of a larger matrix. So any particular \emph{MatrixData} will have a row, column index of the larger matrix.


\begin{flushleft}
\textbf{Template parameters description:}
\end{flushleft}
\begin{description}
	\item[Type] \hfill \\
	Represents the datatype of the matrix, either float or double.
 	
 	\item[Id] \hfill \\
 	The identifier. This identifier will help distinguish what is the matrix data used when it is sent to tasks. For example, with matrix multiplication, you need three matrices $A$, $B$, and $C$. These matrices would be repesented within three different MatrixData as Id=$A$, $B$, or $C$. With the task graph representation, this would form three separate edges to a task.
 	
 	\item[Ord] \hfill \\
 	The matrix order (row-major or column-major)
 \end{description}

\begin{flushleft}
\textbf{Class variables:}
\end{flushleft}

\begin{description}
	\item[rowIdx] \hfill \\
	The row index within the full matrix
	\item[colIdx_] \hfill \\
	The column index within the full matrix
	\item[fullMatrixData] \hfill \\
	The pointer to the full matrix that this MatrixData is representing
	\item[width] \hfill \\
	The width (blockWidth) of this MatrixData
	\item[height] \hfill \\
	The height (blockHeight) of this MatrixData (may be smaller than the height of the full matrix)
	\item[leadingDim] \hfill \\
	The leading dimension for the MatrixData is used to access the data items. For example, to access a particular $i$, $j$ value, you would do the following: \\matrixData[$i \times leadingDim + j$].
\end{description}

Also in \emph{MatrixData} are various getter functions for these variables and a stream operator. There is a special constructor that will be used to convert \emph{MatrixData} to different \textbf{Id}s. This will be used to re-interpret a \emph{MatrixData} instance onto different edges within a task graph. The example for matrix multiplication shows how this can be presented. The \emph{MatrixData} class also implements the function \emph{getMatrixData}, which will return the pointer location to where the \emph{MatrixData} is to be accessed. This can be thought of the pointer location to the row,column sub-block within the full matrix; i.e. fullMatrixData[$row * leadingDim + col$].

In addition we use templates to specify if a matrix is column or row major ordered.


\subsubsection{Operation data classes}

Each BLAS operation will have a container that holds one or more \emph{MatrixData} instances that will be passed to the operation. These will follow the syntax that is used when using BLAS operations. This summer, we will implement many of the required containers for the BLAS functions that need to be implemented.

\begin{description}
	\item[MatrixMulData] \hfill \\
	Holds three \emph{MatrixData} classes:
	\begin{enumerate}
		\item $std::shared\_ptr<MatrixData<Type, `a`, Ord>> matrixA$
		\item $std::shared\_ptr<MatrixData<Type, `b`, Ord>> matrixB$
		\item $std::shared\_ptr<MatrixData<Type, `c`, Ord>> matrixC$
	\end{enumerate}

	This would be represented in the same form as the BLAS GEMM call: $C = \alpha*A \times B + \beta \times C$, where $\alpha$ and $\beta$ are scalar values passed into the constructor of the matrix multiplication task.

\end{description}



\subsection{Linear Algebra Routines}

This section will describe the various linear algebra routines that we may develop over the summer.

\subsubsection{LU Decomposition without pivoting}

\subsubsection{Cholesky Decomposition}

\subsubsection{LU Decomposition with partial pivoting}

\subsubsection{Iterative solvers}



\section{Tentative Implementation Plan}

The current focus at this time will be on CPU-only workflows. If time permits, we might look at some GPU-accelerated designs as well.

\begin{enumerate}
  \item Familiarize with HTGS API
  	\begin{itemize}
  		\item Implement and execute tutorial using C\texttt{++} \footnote{The purpose of this exercise is to understand how to think when it comes to implementing a graph with HTGS. This will translate into the methodology for using Hedgehog as well.}
  		\begin{itemize}
  			\item Download HTGS \url{https://github.com/usnistgov/HTGS}
  			\item Complete Tutorial 1 \url{https://pages.nist.gov/HTGS/doxygen/tutorial1.html}
  			\item Complete Tutorial 2A \url{https://pages.nist.gov/HTGS/doxygen/tutorial2a.html}
  			\item Complete Tutorial 3A \url{https://pages.nist.gov/HTGS/doxygen/tutorial3a.html}
  		\end{itemize} 
  	\end{itemize}
  \item Familiarize with Hedgehog API \footnote{Purpose of this exercise is to understand the differences between using Hedgehog and HTGS}
  	\begin{itemize}
  		\item Convert tutorials 1, 2A, and 3A from HTGS to Hedgehog. (Link to hedgehog repository TBD)
  	\end{itemize}
  \item Matrix Library 
  	\begin{itemize}
  		\item Clone \url{https://gitlab.nist.gov/gitlab/lss/hedgehog-matrixlib.git} \footnote{This repository will represent the MatrixLibrary for Hedgehog.} 
		\item Few things to keep in mind
  		\begin{itemize}
  			\item How the templates for MatrixData affect edges in the task graph
  			\item How to transform a MatrixData to fit into new edges
  		\end{itemize}
  		\item Familiarize with the structure for \emph{MatrixData} and implement tutorial 2a using the library.
  	\end{itemize}
  \item Hedgehog implementation of Matrix Multiplication
  	\begin{itemize}
  		\item Transform tutorial 3a to use the MatrixLibrary instead.
  		\item Add in loading MatrixC into graph and state manager to compute $C = \alpha*A \times B + \beta \times C$
  	\end{itemize}
  \item Linear algebra matrix generation
  	\begin{itemize}
  		\item Create matrix generator for different types of matrices
  		\begin{enumerate}
  			\item Positive definite
  			\item Symmetric
  			\item ...
  		\end{enumerate}
  	\end{itemize}
  \item LU Decomposition without pivoting
  	\begin{itemize}
  		\item Familiarize with block LU decomposition and block+panel LU decomposition routines. We will most likely focus on the block+panel variant.
  		\item Develop framework for linear algebra \footnote{This design will form the basis for all Linear Algebra routines and will be borrowed for future development. So a lot of time will probably be spent designing the framework.}
  		\item Implementation using MatrixLibrary 
  	\end{itemize}
  \item Cholesky decomposition
  	\begin{itemize}
  		\item Using framework developed from LU decomposition, analyze strategy for developing Cholesky decomposition
  		\item Implementation using MatrixLibrary
  	\end{itemize}
  \item LU Decomposition with partial pivoting
  	\begin{itemize}
  		\item Analyze the row swap task and how it will be represented in the original graph
  		\item Implementation using MatrixLibrary
  	\end{itemize}
  \item Iterative Solvers
  	\begin{itemize}
  		\item Jacoobi method
  		\item Conjugate gradient method
  	\end{itemize}
  
  

\end{enumerate}

\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliography.bib}

\end{document}
